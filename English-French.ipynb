{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b58d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9bda8",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc9b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize all variables \n",
    "input_texts=[]\n",
    "target_texts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ae9403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "\n",
      "French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "\n",
      "English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "\n",
      "French sample 2:  les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "f1 = open(r\"small_vocab_en.txt\")\n",
    "input_texts = f1.readlines()\n",
    "f1.close()\n",
    "\n",
    "# Load French data\n",
    "f2 = open(r\"small_vocab_fr.txt\")\n",
    "target_texts = f2.readlines()\n",
    "f2.close()\n",
    "\n",
    "#printing some example data\n",
    "for sample_i in range(2):\n",
    "    print('English sample {}:  {}'.format(sample_i + 1, input_texts[sample_i]))\n",
    "    print('French sample {}:  {}\\n'.format(sample_i + 1, target_texts[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8f64c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd23677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing data\n",
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(input_texts)\n",
    "prepro_eng = eng_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "fre_tokenizer = Tokenizer()\n",
    "fre_tokenizer.fit_on_texts(target_texts)\n",
    "prepro_fre = fre_tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f80e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding all tokenized texts to equal length\n",
    "prepro_eng = pad_sequences(prepro_eng,padding='post')\n",
    "prepro_fre = pad_sequences(prepro_fre,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a788de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 345\n"
     ]
    }
   ],
   "source": [
    "#printing highest length of a sentence and vocabulary size\n",
    "max_english_sequence_length = prepro_eng.shape[1]\n",
    "max_french_sequence_length = prepro_fre.shape[1]\n",
    "english_vocab_size = len(eng_tokenizer.word_index)\n",
    "french_vocab_size = len(fre_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e6d54",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b5f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Loaded\n"
     ]
    }
   ],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    # Embedding\n",
    "    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\n",
    "                         input_shape=input_shape[1:]))\n",
    "    # Encoder\n",
    "    model.add(Bidirectional(GRU(128)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # Decoder\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print('Final Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d908f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 15, 128)           25600     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256)               198144    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " repeat_vector (RepeatVecto  (None, 21, 256)           0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 21, 256)           296448    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 21, 512)           131584    \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 512)           0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 21, 346)           177498    \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 829274 (3.16 MB)\n",
      "Trainable params: 829274 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Initialising Model\n",
    "translator = model_final(prepro_eng.shape, prepro_fre.shape[1], len(eng_tokenizer.word_index)+1, len(fre_tokenizer.word_index)+1)\n",
    "translator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61813d6a",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f179c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "73/73 [==============================] - 124s 2s/step - loss: 2.8367 - accuracy: 0.4463 - val_loss: 1.9460 - val_accuracy: 0.5253\n",
      "Epoch 2/25\n",
      "73/73 [==============================] - 119s 2s/step - loss: 1.7078 - accuracy: 0.5650 - val_loss: 1.4027 - val_accuracy: 0.6316\n",
      "Epoch 3/25\n",
      "73/73 [==============================] - 120s 2s/step - loss: 1.3571 - accuracy: 0.6357 - val_loss: 1.1803 - val_accuracy: 0.6725\n",
      "Epoch 4/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 1.1805 - accuracy: 0.6703 - val_loss: 1.0214 - val_accuracy: 0.7062\n",
      "Epoch 5/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 1.0951 - accuracy: 0.6875 - val_loss: 0.9553 - val_accuracy: 0.7232\n",
      "Epoch 6/25\n",
      "73/73 [==============================] - 119s 2s/step - loss: 0.9511 - accuracy: 0.7205 - val_loss: 0.8308 - val_accuracy: 0.7486\n",
      "Epoch 7/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.8983 - accuracy: 0.7305 - val_loss: 0.7621 - val_accuracy: 0.7633\n",
      "Epoch 8/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.7834 - accuracy: 0.7592 - val_loss: 0.7146 - val_accuracy: 0.7781\n",
      "Epoch 9/25\n",
      "73/73 [==============================] - 119s 2s/step - loss: 0.7048 - accuracy: 0.7799 - val_loss: 0.6047 - val_accuracy: 0.8090\n",
      "Epoch 10/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.6547 - accuracy: 0.7928 - val_loss: 0.5081 - val_accuracy: 0.8380\n",
      "Epoch 11/25\n",
      "73/73 [==============================] - 122s 2s/step - loss: 0.5606 - accuracy: 0.8219 - val_loss: 0.4573 - val_accuracy: 0.8567\n",
      "Epoch 12/25\n",
      "73/73 [==============================] - 121s 2s/step - loss: 0.4925 - accuracy: 0.8432 - val_loss: 0.3870 - val_accuracy: 0.8761\n",
      "Epoch 13/25\n",
      "73/73 [==============================] - 121s 2s/step - loss: 0.6450 - accuracy: 0.8057 - val_loss: 0.7058 - val_accuracy: 0.7785\n",
      "Epoch 14/25\n",
      "73/73 [==============================] - 119s 2s/step - loss: 0.6073 - accuracy: 0.8058 - val_loss: 0.4019 - val_accuracy: 0.8729\n",
      "Epoch 15/25\n",
      "73/73 [==============================] - 121s 2s/step - loss: 0.4594 - accuracy: 0.8523 - val_loss: 0.3236 - val_accuracy: 0.8991\n",
      "Epoch 16/25\n",
      "73/73 [==============================] - 122s 2s/step - loss: 0.3768 - accuracy: 0.8809 - val_loss: 0.2849 - val_accuracy: 0.9140\n",
      "Epoch 17/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.3333 - accuracy: 0.8966 - val_loss: 0.2432 - val_accuracy: 0.9305\n",
      "Epoch 18/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.3011 - accuracy: 0.9091 - val_loss: 0.2650 - val_accuracy: 0.9207\n",
      "Epoch 19/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.3112 - accuracy: 0.9037 - val_loss: 0.1934 - val_accuracy: 0.9453\n",
      "Epoch 20/25\n",
      "73/73 [==============================] - 118s 2s/step - loss: 0.2380 - accuracy: 0.9298 - val_loss: 0.1799 - val_accuracy: 0.9488\n",
      "Epoch 21/25\n",
      "73/73 [==============================] - 117s 2s/step - loss: 0.2176 - accuracy: 0.9361 - val_loss: 0.1722 - val_accuracy: 0.9500\n",
      "Epoch 22/25\n",
      "73/73 [==============================] - 116s 2s/step - loss: 0.1987 - accuracy: 0.9418 - val_loss: 0.1465 - val_accuracy: 0.9586\n",
      "Epoch 23/25\n",
      "73/73 [==============================] - 116s 2s/step - loss: 0.1868 - accuracy: 0.9453 - val_loss: 0.1572 - val_accuracy: 0.9557\n",
      "Epoch 24/25\n",
      "73/73 [==============================] - 119s 2s/step - loss: 0.1747 - accuracy: 0.9486 - val_loss: 0.1367 - val_accuracy: 0.9615\n",
      "Epoch 25/25\n",
      "73/73 [==============================] - 116s 2s/step - loss: 0.1636 - accuracy: 0.9519 - val_loss: 0.1448 - val_accuracy: 0.9591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23409d2bf10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting data into testing and training\n",
    "x_train, x_test, y_train, y_test = train_test_split(prepro_eng,prepro_fre,test_size=0.33,random_state=42)\n",
    "\n",
    "#Fitting the Model\n",
    "translator.fit(x_train, y_train, batch_size=1024, epochs=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa266c",
   "metadata": {},
   "source": [
    "# Testing  the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1beae64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss and test accuracy are:\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.1373 - accuracy: 0.9608\n",
      "[0.1372891217470169, 0.9607860445976257]\n"
     ]
    }
   ],
   "source": [
    "#Finding loss and accuracy for test data\n",
    "print(\"test loss and test accuracy are:\")\n",
    "results = translator.evaluate(x_test,y_test,batch_size=1024)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219f76f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for converting ids back to text\n",
    "def logits_to_text(logits, tokenizer ,mode='default'):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    if mode == 'probability_scores':\n",
    "        return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "    else :\n",
    "        return ' '.join([index_to_words[prediction] for prediction in logits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32684ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "English :   china is usually busy during september but it is sometimes cold in spring <PAD> <PAD>\n",
      "Machine Translation :   chine est gã©nã©ralement occupã© en septembre mais il est parfois froid au printemps <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Correct Translation :   chine est gã©nã©ralement occupã© en septembre mais il est parfois froid au printemps <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "*******************************************************************************************\n",
      "English :   he dislikes pears and peaches <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Machine Translation :   il n'aime les poires et les pãªches <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Correct Translation :   il aime pas les poires et les pãªches <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "*******************************************************************************************\n",
      "English :   the united states is sometimes rainy during january but it is mild in may <PAD>\n",
      "Machine Translation :   les ã©tats unis est parfois pluvieux en janvier mais il est doux en mai <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Correct Translation :   les ã©tats unis est parfois pluvieux en janvier mais il est doux en mai <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#showing 3 samples and their translations from model\n",
    "predictions = translator.predict(x_test[:3])\n",
    "for i in range(3):\n",
    "    print(\"English :  \",logits_to_text(x_test[i], eng_tokenizer))\n",
    "    print(\"Machine Translation :  \",logits_to_text(predictions[i], fre_tokenizer, mode='probability_scores'))\n",
    "    print(\"Correct Translation :  \",logits_to_text(y_test[i], fre_tokenizer))\n",
    "    print(\"*******************************************************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
